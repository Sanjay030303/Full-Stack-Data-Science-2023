{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM706Tg+VA3NCUAVrnGZqmp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sanjay030303/Full-Stack-Data-Science-2023/blob/main/DL_ASSIGNMENT_7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oEbbcABmu5Cw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Can you think of a few applications for a sequence-to-sequence RNN? What about a sequence-to-vector RNN, and a vector-to-sequence RNN?**\n",
        "   - **Sequence-to-sequence RNN:** Machine translation, text summarization, and chatbots.\n",
        "   - **Sequence-to-vector RNN:** Sentiment analysis, sequence classification, and feature extraction from sequences.\n",
        "   - **Vector-to-sequence RNN:** Image captioning, music generation from a theme, and text generation from a prompt.\n",
        "\n",
        "2. **How many dimensions must the inputs of an RNN layer have? What does each dimension represent? What about its outputs?**\n",
        "   - RNN inputs have three dimensions: (batch_size, timesteps, features).\n",
        "     - **batch_size:** Number of sequences in a batch.\n",
        "     - **timesteps:** Length of each sequence.\n",
        "     - **features:** Number of features per timestep.\n",
        "   - RNN outputs can also have three dimensions (batch_size, timesteps, units) if `return_sequences=True`, or two dimensions (batch_size, units) if `return_sequences=False`.\n",
        "\n",
        "3. **If you want to build a deep sequence-to-sequence RNN, which RNN layers should have return_sequences=True? What about a sequence-to-vector RNN?**\n",
        "   - For a **sequence-to-sequence RNN**, all RNN layers except the last one should have `return_sequences=True`.\n",
        "   - For a **sequence-to-vector RNN**, only the last layer should have `return_sequences=False`.\n",
        "\n",
        "4. **Suppose you have a daily univariate time series, and you want to forecast the next seven days. Which RNN architecture should you use?**\n",
        "   - Use a sequence-to-sequence RNN, such as an encoder-decoder architecture, to predict the next seven days.\n",
        "\n",
        "5. **What are the main difficulties when training RNNs? How can you handle them?**\n",
        "   - **Difficulties:**\n",
        "     - Vanishing and exploding gradients.\n",
        "     - Long training times.\n",
        "     - Difficulty in capturing long-term dependencies.\n",
        "   - **Solutions:**\n",
        "     - Use LSTM or GRU cells to handle vanishing gradients.\n",
        "     - Gradient clipping to address exploding gradients.\n",
        "     - Use of advanced optimizers like Adam.\n",
        "     - Regularization techniques such as dropout.\n",
        "\n",
        "6. **Can you sketch the LSTM cellâ€™s architecture?**\n",
        "   - The LSTM cell includes three main gates:\n",
        "     - **Forget gate:** Decides what information to discard from the cell state.\n",
        "     - **Input gate:** Decides which new information to add to the cell state.\n",
        "     - **Output gate:** Decides what the next hidden state should be.\n",
        "     - The LSTM cell uses these gates to maintain and update the cell state, which helps in preserving long-term dependencies.\n",
        "\n",
        "7. **Why would you want to use 1D convolutional layers in an RNN?**\n",
        "   - 1D convolutional layers can be used to extract local patterns from sequences, reduce sequence length, and preprocess data before feeding it into RNN layers. This can improve efficiency and performance.\n",
        "\n",
        "8. **Which neural network architecture could you use to classify videos?**\n",
        "   - A combination of CNNs (to extract spatial features from video frames) and RNNs (to capture temporal dependencies) can be used to classify videos. 3D CNNs or models like ConvLSTM can also be effective.\n",
        "\n",
        "9. **Train a classification model for the SketchRNN dataset, available in TensorFlow Datasets.**\n",
        "   ```python\n",
        "   import tensorflow as tf\n",
        "   from tensorflow.keras import layers, models\n",
        "\n",
        "   # Load the SketchRNN dataset\n",
        "   dataset, info = tfds.load('sketch_rnn/full', with_info=True, as_supervised=True)\n",
        "   train_dataset, test_dataset = dataset['train'], dataset['test']\n",
        "\n",
        "   # Preprocess the data\n",
        "   def preprocess(image, label):\n",
        "       image = tf.image.resize(image, [28, 28])\n",
        "       image = tf.expand_dims(image, axis=-1)  # Add channel dimension\n",
        "       image = tf.cast(image, tf.float32) / 255.0\n",
        "       return image, label\n",
        "\n",
        "   train_dataset = train_dataset.map(preprocess).batch(32).shuffle(1000)\n",
        "   test_dataset = test_dataset.map(preprocess).batch(32)\n",
        "\n",
        "   # Build the CNN model\n",
        "   model = models.Sequential([\n",
        "       layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "       layers.MaxPooling2D((2, 2)),\n",
        "       layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "       layers.MaxPooling2D((2, 2)),\n",
        "       layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "       layers.Flatten(),\n",
        "       layers.Dense(64, activation='relu'),\n",
        "       layers.Dense(info.features['label'].num_classes, activation='softmax')\n",
        "   ])\n",
        "\n",
        "   # Compile and train the model\n",
        "   model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "   model.fit(train_dataset, epochs=5, validation_data=test_dataset)\n",
        "\n",
        "   # Evaluate the model\n",
        "   test_loss, test_acc = model.evaluate(test_dataset)\n",
        "   print(f'Test accuracy: {test_acc}')\n",
        "   ```"
      ],
      "metadata": {
        "id": "nmUV5WIcu50E"
      }
    }
  ]
}